<b>Hallucination (LLM):</b> A response that looks plausible and is delivered with full confidence, yet is wholly or partly fabricated and unsupported by any real source. This is especially problematic in scientific settings, where downstream decisions rely on accuracy.