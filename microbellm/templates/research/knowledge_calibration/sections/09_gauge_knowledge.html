<p>To gauge how much an LLM "knows" about each invented microbe, we run the same handful of questions against every name in the library. Because the wording never changes—only the species placeholder—the answers are directly comparable. For each reply we record whether the model offers concrete details, hedges with uncertainty, or immediately admits it has no information. Summarising those outcomes across our realism gradient tells us exactly when the model starts hallucinating and when it sensibly says "I'm not sure."</p>