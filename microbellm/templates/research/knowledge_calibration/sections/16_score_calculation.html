<p>To compare models on a single scale we devised a "hallucination-avoidance" score. Each response earns three points if the model refuses or returns <code>NA</code>, two points for a self-declared limited answer, one point for intermediate, and zero when it claims extensive knowledge. We then sum those points for every fictional name and divide by the number of prompts, yielding an average that ranges from 0 (pure fantasy) to 3 (perfect restraint). Thus a model that usually says "I don't know" or "limited" on fake species will hover near the high end of the scale, while one that invents rich detail will drift toward zero.</p>