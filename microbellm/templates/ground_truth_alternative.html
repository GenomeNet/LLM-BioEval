{% extends "base.html" %}

{% block title %}Model Accuracy (Legacy) - MicrobeBench{% endblock %}

{% block content %}
<h1>Model Accuracy Analysis (Legacy Method)</h1>

<div class="explanation-section">
    <div class="explanation-grid">
        <div class="explanation-box purpose-box">
            <h3><i class="fas fa-bullseye"></i> Purpose</h3>
            <p>This page evaluates model performance using the legacy metric calculation method. It compares model predictions against a selected ground truth dataset to produce the following metrics:</p>
            <ul class="purpose-list">
                <li><strong>Balanced Accuracy:</strong> Calculated as the average of sensitivity and specificity for each class.</li>
                <li><strong>Precision:</strong> Macro-averaged precision for multi-class phenotypes.</li>
            </ul>
            <p class="note"><em>Note: This implementation is a direct port of the original Python/Django script for calculating metrics.</em></p>
        </div>
        
        <div class="explanation-box interpretation-box">
            <h3><i class="fas fa-chart-bar"></i> How to Interpret Results</h3>
            <div class="metric-interpretation">
                <h4>Performance Levels (Balanced Accuracy):</h4>
                <div class="performance-row excellent"><span class="performance-range">â‰¥ 0.9</span> <span class="performance-label">Excellent</span></div>
                <div class="performance-row good"><span class="performance-range">0.7-0.9</span> <span class="performance-label">Good</span></div>
                <div class="performance-row moderate"><span class="performance-range">0.5-0.7</span> <span class="performance-label">Moderate</span></div>
                <div class="performance-row poor"><span class="performance-range">< 0.5</span> <span class="performance-label">Poor</span></div>
            </div>
             <p class="note">Precision is on a 0 to 1 scale. Higher is better.</p>
        </div>
    </div>
</div>

<div class="row mb-4">
    <div class="col-md-12">
        <div class="p-3" style="background-color: #f8f9fa; border: 1px solid #e9ecef; border-radius: 8px;">
            <div class="row align-items-end">
                <div class="col-md-8">
                    <label for="groundTruthDataset">Ground Truth Dataset</label>
                    <select class="form-control" id="groundTruthDataset">
                        <option value="">Loading datasets...</option>
                    </select>
                    <small class="text-muted mt-1 d-block" id="datasetInfo"></small>
                </div>
                <div class="col-md-4">
                    <button class="btn btn-primary btn-block" onclick="analyzeAccuracy()" id="analyzeBtn" disabled>
                        <i class="fas fa-chart-line"></i> Analyze Accuracy
                    </button>
                </div>
            </div>
        </div>
    </div>
</div>

<div id="analysisResults" style="display: none;">
    <div class="card">
        <div class="card-header">
            <h5 class="mb-0"><i class="fas fa-microscope"></i> Detailed Metrics by Model</h5>
        </div>
        <div class="card-body">
            <div id="detailedAccuracy"></div>
        </div>
    </div>
</div>

<div style="height: 600px;"></div>

<style>
/* Explanation Section Styles */
.explanation-section { margin-bottom: 30px; }
.explanation-grid { display: grid; grid-template-columns: 1fr 1fr; gap: 20px; }
@media (max-width: 1024px) { .explanation-grid { grid-template-columns: 1fr; } }
.explanation-box { background: white; border: 1px solid #dee2e6; border-radius: 8px; padding: 20px; box-shadow: 0 2px 4px rgba(0,0,0,0.05); }
.explanation-box h3 { margin: 0 0 15px 0; color: #2c3e50; font-size: 18px; display: flex; align-items: center; gap: 10px; }
.explanation-box h3 i { font-size: 20px; opacity: 0.7; }
.purpose-box { background: #f0f7ff; border-color: #b3d9ff; }
.purpose-box h3 { color: #0056b3; }
.interpretation-box { background: #f8f9fa; }
.explanation-box p { margin: 0 0 10px 0; line-height: 1.6; color: #495057; font-size: 14px; }
.purpose-list { margin: 10px 0; padding-left: 20px; }
.purpose-list li { margin-bottom: 8px; color: #495057; font-size: 14px; }
.note { margin-top: 15px; padding: 10px; background: #e3f2fd; border-radius: 4px; font-size: 13px; }
.metric-interpretation h4 { margin: 0 0 10px 0; font-size: 15px; font-weight: 600; }
.performance-row { display: grid; grid-template-columns: 80px 1fr; align-items: center; padding: 10px 12px; margin-bottom: 8px; border-radius: 6px; font-size: 13px; }
.performance-row.excellent { background: #d4edda; }
.performance-row.good { background: #d1ecf1; }
.performance-row.moderate { background: #fff3cd; }
.performance-row.poor { background: #f8d7da; }
.performance-range { font-weight: 700; font-family: monospace; }
.performance-label { font-weight: 600; }

/* Metrics table styling */
.accuracy-table { font-size: 13px; }
.accuracy-table th { background-color: #f8f9fa; font-weight: 600; }
.metric-cell { text-align: center; }
.metric-value { font-weight: 600; display: inline-block; padding: 4px 8px; border-radius: 4px; }
.excellent { background-color: #d4edda; color: #155724; }
.good { background-color: #d1ecf1; color: #0c5460; }
.moderate { background-color: #fff3cd; color: #856404; }
.poor { background-color: #f8d7da; color: #721c24; }
.na-value { background-color: #e2e3e5; color: #6c757d; font-style: italic; }
</style>
{% endblock %}

{% block scripts %}
<script>
// Global variables
let groundTruthDatasets = [];
let predictionData = null;
let currentMetrics = null;
let fieldDefinitions = {};
let groundTruthMap = {};
let predictionDataPromise = null;

// Initialize on page load
document.addEventListener('DOMContentLoaded', function() {
    loadGroundTruthDatasets();
    predictionDataPromise = loadPredictionData();
});

async function loadGroundTruthDatasets() {
    try {
        const response = await fetch('/api/ground_truth/datasets');
        const result = await response.json();
        if (result.success) {
            groundTruthDatasets = result.datasets;
            const select = document.getElementById('groundTruthDataset');
            if (result.datasets.length === 0) {
                select.innerHTML = '<option value="">No ground truth datasets available</option>';
                document.getElementById('datasetInfo').innerHTML = '<i class="fas fa-info-circle"></i> Please import ground truth data first.';
            } else {
                let html = '<option value="">Select dataset...</option>';
                result.datasets.forEach(dataset => {
                    html += `<option value="${dataset.dataset_name}" data-template="${dataset.template_name}" data-species-count="${dataset.species_count}">${dataset.dataset_name}</option>`;
                });
                select.innerHTML = html;
                document.getElementById('analyzeBtn').disabled = false;
            }
            select.addEventListener('change', function() {
                if (this.value) {
                    const selectedOption = this.options[this.selectedIndex];
                    const speciesCount = selectedOption.getAttribute('data-species-count');
                    const templateName = selectedOption.getAttribute('data-template');
                    document.getElementById('datasetInfo').innerHTML = `<i class="fas fa-dna"></i> ${speciesCount} species | <i class="fas fa-file-alt"></i> Template: ${templateName}`;
                } else {
                    document.getElementById('datasetInfo').textContent = '';
                }
            });

            if (result.datasets.length === 1) {
                select.value = result.datasets[0].dataset_name;
                select.dispatchEvent(new Event('change'));
                analyzeAccuracy();
            }
        }
    } catch (error) {
        console.error('Error loading datasets:', error);
        document.getElementById('groundTruthDataset').innerHTML = '<option value="">Error loading datasets</option>';
    }
}

async function loadPredictionData() {
    try {
        const response = await fetch('/api/phenotype_analysis');
        const result = await response.json();
        if (!result.error && result.data) {
            predictionData = result.data;
        }
    } catch (error) {
        console.error('Error loading prediction data:', error);
    }
}

async function analyzeAccuracy() {
    const datasetSelect = document.getElementById('groundTruthDataset');
    const datasetName = datasetSelect.value;
    if (!datasetName) {
        alert('Please select a ground truth dataset');
        return;
    }
    const selectedOption = datasetSelect.options[datasetSelect.selectedIndex];
    const templateName = selectedOption.getAttribute('data-template');

    await predictionDataPromise;

    if (!templateName || !predictionData) {
        alert('Required data is missing. Please select a valid dataset and ensure predictions are loaded.');
        return;
    }

    const analyzeBtn = document.getElementById('analyzeBtn');
    analyzeBtn.disabled = true;
    analyzeBtn.innerHTML = '<i class="fas fa-spinner fa-spin"></i> Analyzing...';

    try {
        const templateResponse = await fetch(`/api/template_field_definitions?template=${templateName}`);
        const templateResult = await templateResponse.json();
        fieldDefinitions = templateResult.success ? templateResult.field_definitions : {};

        const groundTruthResponse = await fetch(`/api/ground_truth/data?dataset=${datasetName}&per_page=10000`);
        const groundTruthResult = await groundTruthResponse.json();
        if (!groundTruthResult.success) throw new Error('Failed to load ground truth data');

        groundTruthMap = {};
        groundTruthResult.data.forEach(item => {
            groundTruthMap[item.binomial_name.toLowerCase()] = item;
        });

        currentMetrics = calculateLegacyMetrics(predictionData, groundTruthMap, fieldDefinitions);
        displayAccuracyResults(currentMetrics, fieldDefinitions);
        document.getElementById('analysisResults').style.display = 'block';

    } catch (error) {
        alert('Error analyzing accuracy: ' + error.message);
    } finally {
        analyzeBtn.disabled = false;
        analyzeBtn.innerHTML = '<i class="fas fa-chart-line"></i> Analyze Accuracy';
    }
}

function normalizeValue(value) {
    if (value === null || value === undefined || value === 'N/A' || value === 'null') return '';
    return String(value).trim();
}

function calculateLegacyMetrics(predictionData, groundTruthMap, fieldDefinitions) {
    const results = [];
    const phenotypeFields = Object.keys(fieldDefinitions);
    const allPredictions = Object.values(predictionData).flat();

    const models = [...new Set(allPredictions.map(p => p.model))];

    phenotypeFields.forEach(phenotype => {
        models.forEach(model => {
            const modelPredictions = allPredictions.filter(p => p.model === model);
            
            let true_values = [];
            let pred_values = [];

            modelPredictions.forEach(pred => {
                const speciesName = pred.binomial_name?.toLowerCase();
                if (speciesName && groundTruthMap[speciesName]) {
                    const truth = groundTruthMap[speciesName];
                    const true_val = normalizeValue(truth[phenotype]);
                    const pred_val = normalizeValue(pred[phenotype]);
                    
                    if (true_val !== '' && pred_val !== '') {
                        true_values.push(true_val);
                        pred_values.push(pred_val);
                    }
                }
            });

            if (true_values.length > 0) {
                const metrics = calcMetrics(pred_values, true_values);
                if (metrics) {
                    results.push({
                        Model: model,
                        Target: phenotype,
                        BalancedAcc: metrics.balanced_accuracy,
                        Precision: metrics.precision,
                        SampleSize: metrics.sampleSize
                    });
                }
            }
        });
    });
    return results;
}

function calcMetrics(pred_values, true_values) {
    const convertToLogical = (val) => {
        const lower = String(val).toLowerCase();
        if (['true', 't', '1', 'yes'].includes(lower)) return true;
        if (['false', 'f', '0', 'no'].includes(lower)) return false;
        return null;
    };

    if (true_values.length === 0 || [...new Set(true_values)].length < 2) {
        return { balanced_accuracy: NaN, precision: NaN, sampleSize: 0 };
    }

    const all_unique_values = [...new Set([...true_values, ...pred_values])];
    const is_binary = all_unique_values.every(v => convertToLogical(v) !== null);

    if (is_binary) {
        const true_logical = true_values.map(convertToLogical);
        const pred_logical = pred_values.map(convertToLogical);
        let tp = 0, tn = 0, fp = 0, fn = 0;
        for (let i = 0; i < true_logical.length; i++) {
            if (true_logical[i] === true && pred_logical[i] === true) tp++;
            else if (true_logical[i] === false && pred_logical[i] === false) tn++;
            else if (true_logical[i] === false && pred_logical[i] === true) fp++;
            else if (true_logical[i] === true && pred_logical[i] === false) fn++;
        }
        const sensitivity = (tp + fn > 0) ? tp / (tp + fn) : 0;
        const specificity = (tn + fp > 0) ? tn / (tn + fp) : 0;
        const balanced_acc = (sensitivity + specificity) / 2;
        const precision = (tp + fp > 0) ? tp / (tp + fp) : 0;
        return { balanced_accuracy: balanced_acc, precision: precision, sampleSize: true_values.length };
    } else {
        // Multi-class case
        const all_labels = [...new Set([...true_values, ...pred_values])].sort();
        const label_map = Object.fromEntries(all_labels.map((l, i) => [l, i]));
        const num_labels = all_labels.length;
        const cm = Array(num_labels).fill(0).map(() => Array(num_labels).fill(0));
        
        for (let i = 0; i < true_values.length; i++) {
            const true_idx = label_map[true_values[i]];
            const pred_idx = label_map[pred_values[i]];
            if (true_idx !== undefined && pred_idx !== undefined) {
                cm[true_idx][pred_idx]++;
            }
        }
        
        const cm_sum = cm.flat().reduce((a, b) => a + b, 0);
        let balanced_acc_per_class = [];
        let precision_per_class = [];
        
        const true_labels_in_data = [...new Set(true_values)];

        for (let i = 0; i < num_labels; i++) {
            const label = all_labels[i];
            if (!true_labels_in_data.includes(label)) continue;

            const tp = cm[i][i];
            const row_sum = cm[i].reduce((a, b) => a + b, 0);
            const col_sum = cm.reduce((sum, row) => sum + row[i], 0);
            const fn = row_sum - tp;
            const fp = col_sum - tp;
            const tn = cm_sum - tp - fn - fp;
            
            const sensitivity = (tp + fn > 0) ? tp / (tp + fn) : 0;
            const specificity = (tn + fp > 0) ? tn / (tn + fp) : 0;
            balanced_acc_per_class.push((sensitivity + specificity) / 2);
            
            const precision_i = (tp + fp > 0) ? tp / (tp + fp) : 0;
            precision_per_class.push(precision_i);
        }

        const balanced_acc = balanced_acc_per_class.length > 0 ? balanced_acc_per_class.reduce((a, b) => a + b, 0) / balanced_acc_per_class.length : NaN;
        const precision = precision_per_class.length > 0 ? precision_per_class.reduce((a, b) => a + b, 0) / precision_per_class.length : NaN;

        return { balanced_accuracy: balanced_acc, precision: precision, sampleSize: true_values.length };
    }
}

function displayAccuracyResults(metrics, fieldDefinitions) {
    const models = [...new Set(metrics.map(m => m.Model))].sort();
    const phenotypes = [...new Set(metrics.map(m => m.Target))].sort();

    let html = '<div class="table-responsive"><table class="table table-bordered accuracy-table">';
    html += '<thead><tr><th>Model</th>';
    phenotypes.forEach(pheno => {
        html += `<th colspan="3" class="text-center">${pheno.replace(/_/g, ' ')}</th>`;
    });
    html += '</tr><tr><th></th>';
    phenotypes.forEach(() => {
        html += '<th>Balanced Acc.</th><th>Precision</th><th>N</th>';
    });
    html += '</tr></thead><tbody>';

    models.forEach(model => {
        html += `<tr><td><strong>${model}</strong></td>`;
        phenotypes.forEach(pheno => {
            const metric = metrics.find(m => m.Model === model && m.Target === pheno);
            if (metric) {
                const acc = metric.BalancedAcc;
                const prec = metric.Precision;
                const acc_val = isNaN(acc) ? 'N/A' : acc.toFixed(3);
                const prec_val = isNaN(prec) ? 'N/A' : prec.toFixed(3);
                const acc_class = isNaN(acc) ? 'na-value' : getPerformanceClass(acc);

                html += `<td class="metric-cell"><span class="metric-value ${acc_class}">${acc_val}</span></td>`;
                html += `<td class="metric-cell"><span class="metric-value">${prec_val}</span></td>`;
                html += `<td class="metric-cell">${metric.SampleSize}</td>`;
            } else {
                html += '<td colspan="3" class="text-center na-value">N/A</td>';
            }
        });
        html += '</tr>';
    });

    html += '</tbody></table></div>';
    document.getElementById('detailedAccuracy').innerHTML = html;
}

function getPerformanceClass(value) {
    if (value >= 0.9) return 'excellent';
    if (value >= 0.7) return 'good';
    if (value >= 0.5) return 'moderate';
    return 'poor';
}
</script>
{% endblock %}
